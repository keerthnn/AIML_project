{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLi7en0YTrX3qW8IRiv11B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keerthnn/AIML_project/blob/main/Astar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.A Star**"
      ],
      "metadata": {
        "id": "anSERvtJZljx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSGZUYmATt0D",
        "outputId": "ee5108f5-c54a-4bfa-9b97-a9df2d92279a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path Found: ['A', 'F', 'G', 'I', 'J']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'F', 'G', 'I', 'J']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "def astarAlgo(start_node, stop_node):\n",
        "    open_set = set([start_node])\n",
        "    closed_set = set()\n",
        "    g = {}\n",
        "    parents = {}\n",
        "    g[start_node] = 0\n",
        "    parents[start_node] = start_node\n",
        "\n",
        "    while len(open_set) > 0:\n",
        "        n = None\n",
        "        for v in open_set:\n",
        "            if n is None or g[v] + heuristic(v) < g[n] + heuristic(n):\n",
        "                n = v\n",
        "\n",
        "        if n == stop_node or graph_nodes[n] is None:\n",
        "            pass\n",
        "        else:\n",
        "            for (m, weight) in get_neighbours(n):\n",
        "                if m not in open_set and m not in closed_set:\n",
        "                    open_set.add(m)\n",
        "                    parents[m] = n\n",
        "                    g[m] = g[n] + weight\n",
        "                else:\n",
        "                    if g[m] > g[n] + weight:\n",
        "                        g[m] = g[n] + weight\n",
        "                        parents[m] = n\n",
        "\n",
        "                    if m in closed_set:\n",
        "                        closed_set.remove(m)\n",
        "                        open_set.add(m)\n",
        "\n",
        "        if n is None:\n",
        "            print('Path Doesn\\'t Exist!')\n",
        "            return None\n",
        "\n",
        "        if n == stop_node:\n",
        "            path = []\n",
        "            while parents[n] != n:\n",
        "                path.append(n)\n",
        "                n = parents[n]\n",
        "            path.append(start_node)\n",
        "            path.reverse()\n",
        "            print('Path Found:', format(path))\n",
        "            return path\n",
        "\n",
        "        open_set.remove(n)\n",
        "        closed_set.add(n)\n",
        "\n",
        "    print('Path Doesn\\'t Exist!')\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_neighbours(v):\n",
        "    if v in graph_nodes:\n",
        "        return graph_nodes[v]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def heuristic(n):\n",
        "    H_dist = {\n",
        "        'A': 10,\n",
        "        'B': 8,\n",
        "        'C': 5,\n",
        "        'D': 7,\n",
        "        'E': 3,\n",
        "        'F': 6,\n",
        "        'G': 5,\n",
        "        'H': 4,\n",
        "        'I': 1,\n",
        "        'J': 0\n",
        "    }\n",
        "    return H_dist[n]\n",
        "\n",
        "\n",
        "graph_nodes = {\n",
        "    'A': [('B', 6), ('F', 3)],\n",
        "    'B': [('C', 3), ('D', 2)],\n",
        "    'C': [('D', 1), ('E', 5)],\n",
        "    'D': [('C', 1), ('E', 8)],\n",
        "    'E': [('I', 5), ('J', 5)],\n",
        "    'F': [('G', 1), ('H', 7)],\n",
        "    'G': [('I', 3)],\n",
        "    'H': [('I', 2)],\n",
        "    'I': [('E', 5), ('J', 3)]\n",
        "}\n",
        "\n",
        "astarAlgo('A', 'J')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.AO STAR**"
      ],
      "metadata": {
        "id": "rx_CcyhWZrpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recAOStar(n):\n",
        "    global finalPath\n",
        "    print(\"Expanding Node :\", n)\n",
        "    and_nodes = []\n",
        "    or_nodes = []\n",
        "    if n in allNodes:\n",
        "        if 'AND' in allNodes[n]:\n",
        "            and_nodes = allNodes[n]['AND']\n",
        "        if 'OR' in allNodes[n]:\n",
        "            or_nodes = allNodes[n]['OR']\n",
        "    if len(and_nodes) == 0 and len(or_nodes) == 0:\n",
        "        return\n",
        "    solvable = False\n",
        "    marked = {}\n",
        "    while not solvable:\n",
        "        if len(marked) == len(and_nodes) + len(or_nodes):\n",
        "            min_cost_least, min_cost_group_least = least_cost_group(and_nodes, or_nodes, {})\n",
        "            solvable = True\n",
        "            change_heuristic(n, min_cost_least)\n",
        "            optimal_child_group[n] = min_cost_group_least\n",
        "            continue\n",
        "        min_cost, min_cost_group = least_cost_group(and_nodes, or_nodes, marked)\n",
        "        is_expanded = False\n",
        "\n",
        "        if len(min_cost_group) > 1:\n",
        "            if min_cost_group[0] in allNodes:\n",
        "                is_expanded = True\n",
        "                recAOStar(min_cost_group[0])\n",
        "            if min_cost_group[1] in allNodes:\n",
        "                is_expanded = True\n",
        "                recAOStar(min_cost_group[1])\n",
        "        else:\n",
        "            if min_cost_group in allNodes:\n",
        "                is_expanded = True\n",
        "                recAOStar(min_cost_group)\n",
        "        if is_expanded:\n",
        "            min_cost_verify, min_cost_group_verify = least_cost_group(and_nodes, or_nodes, {})\n",
        "            if min_cost_group == min_cost_group_verify:\n",
        "                solvable = True\n",
        "                change_heuristic(n, min_cost_verify)\n",
        "                optimal_child_group[n] = min_cost_group\n",
        "        else:\n",
        "            solvable = True\n",
        "            change_heuristic(n, min_cost)\n",
        "            optimal_child_group[n] = min_cost_group\n",
        "        marked[min_cost_group] = 1\n",
        "    return heuristic(n)\n",
        "\n",
        "\n",
        "def least_cost_group(and_nodes, or_nodes, marked):\n",
        "    node_wise_cost = {}\n",
        "    for node_pair in and_nodes:\n",
        "        if not node_pair[0] + node_pair[1] in marked:\n",
        "            cost = 0\n",
        "            cost = cost + heuristic(node_pair[0]) + heuristic(node_pair[1]) + 2\n",
        "            node_wise_cost[node_pair[0] + node_pair[1]] = cost\n",
        "    for node in or_nodes:\n",
        "        if not node in marked:\n",
        "            cost = 0\n",
        "            cost = cost + heuristic(node) + 1\n",
        "            node_wise_cost[node] = cost\n",
        "    min_cost = 999999\n",
        "    min_cost_group = None\n",
        "    for costKey in node_wise_cost:\n",
        "        if node_wise_cost[costKey] < min_cost:\n",
        "            min_cost = node_wise_cost[costKey]\n",
        "            min_cost_group = costKey\n",
        "    return [min_cost, min_cost_group]\n",
        "\n",
        "\n",
        "def heuristic(n):\n",
        "    return H_dist[n]\n",
        "\n",
        "\n",
        "def change_heuristic(n, cost):\n",
        "    H_dist[n] = cost\n",
        "    return\n",
        "\n",
        "\n",
        "def print_path(node):\n",
        "    print(optimal_child_group[node], end=\"\")\n",
        "    node = optimal_child_group[node]\n",
        "    if len(node) > 1:\n",
        "        if node[0] in optimal_child_group:\n",
        "            print(\"->\", end=\"\")\n",
        "            print_path(node[0])\n",
        "        if node[1] in optimal_child_group:\n",
        "            print(\"->\", end=\"\")\n",
        "            print_path(node[1])\n",
        "    else:\n",
        "        if node in optimal_child_group:\n",
        "            print(\"->\", end=\"\")\n",
        "            print_path(node)\n",
        "\n",
        "\n",
        "H_dist = {\n",
        "    'A': -1,\n",
        "    'B': 4,\n",
        "    'C': 2,\n",
        "    'D': 3,\n",
        "    'E': 6,\n",
        "    'F': 8,\n",
        "    'G': 2,\n",
        "    'H': 0,\n",
        "    'I': 0,\n",
        "    'J': 0\n",
        "}\n",
        "\n",
        "allNodes = {\n",
        "    'A': {'AND': [('C', 'D')], 'OR': ['B']},\n",
        "    'B': {'OR': ['E', 'F']},\n",
        "    'C': {'AND': [('H', 'I')], 'OR': ['G']},\n",
        "    'D': {'OR': ['J']}\n",
        "}\n",
        "\n",
        "optimal_child_group = {}\n",
        "optimal_cost = recAOStar('A')\n",
        "print('Nodes Which Give Optimal Cost Are')\n",
        "print_path('A')\n",
        "print('\\nOptimal Cost Is:', optimal_cost)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFK49zzcWqCi",
        "outputId": "135a2529-6740-4dfc-9bb7-3c315ceaba26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expanding Node : A\n",
            "Expanding Node : B\n",
            "Expanding Node : C\n",
            "Expanding Node : D\n",
            "Nodes Which Give Optimal Cost Are\n",
            "CD->HI->J\n",
            "Optimal Cost Is: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Decision Tree**"
      ],
      "metadata": {
        "id": "HIq1ugEQZvxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "def infoGain(P, N):\n",
        "    # Calculate Information Gain Or Class Entropy\n",
        "    return -P / (P + N) * math.log2(P / (P + N)) - N / (P + N) * math.log2(N / (P + N))\n",
        "\n",
        "def insertNode(tree, addTo, Node):\n",
        "    for k, v in tree.items():\n",
        "        # Traversal Of Tree\n",
        "        if isinstance(v, dict):\n",
        "            tree[k] = insertNode(v, addTo, Node)\n",
        "        if addTo in tree:\n",
        "            # If d Is Found then Add Node\n",
        "            if isinstance(tree[addTo], dict):\n",
        "                tree[addTo][Node] = 'None'\n",
        "            else:\n",
        "                tree[addTo] = {Node: 'None'}\n",
        "    return tree\n",
        "\n",
        "def insertConcept(tree, addTo, Node):\n",
        "    for k, v in tree.items():\n",
        "        # Traversal Of Tree\n",
        "        if isinstance(v, dict):\n",
        "            tree[k] = insertConcept(v, addTo, Node)\n",
        "        if addTo in tree:\n",
        "            # If d Is Found Then Add Node\n",
        "            tree[addTo] = Node\n",
        "    return tree\n",
        "\n",
        "def getNextNode(data, AttributeList, concept, conceptVals, tree, addTo):\n",
        "    Total = data.shape[0]\n",
        "    if Total == 0:\n",
        "        # If Attributes Are Empty, Then Return Current Value Of Tree\n",
        "        return tree\n",
        "\n",
        "    countC = {}\n",
        "    for cVal in conceptVals:\n",
        "        # If Example Is Positive, Then Return Positive, If Negative, Then Return Negative\n",
        "        dataCC = data[data[concept] == cVal]\n",
        "        # Get Data For Specific Concept\n",
        "        countC[cVal] = dataCC.shape[0]\n",
        "        # Get The Count Of Data For Specific Concept\n",
        "\n",
        "    if countC[conceptVals[0]] == 0:\n",
        "        # If All Examples Are Positive (Not Negative), Return Single Node Positive\n",
        "        tree = insertConcept(tree, addTo, conceptVals[1])\n",
        "        return tree\n",
        "\n",
        "    if countC[conceptVals[1]] == 0:\n",
        "        # If All Examples Are Negative (Not Positive), Return Single Node Negative\n",
        "        tree = insertConcept(tree, addTo, conceptVals[0])\n",
        "        return tree\n",
        "\n",
        "    ClassEntropy = infoGain(countC[conceptVals[0]], countC[conceptVals[1]])\n",
        "    # Calculate Class Entropy For Data\n",
        "\n",
        "    Attr = {}\n",
        "    # Attribute Dictionary Holding List Of Possible Values\n",
        "    for a in AttributeList:\n",
        "        Attr[a] = list(set(data[a]))\n",
        "\n",
        "    AttrCount = {}\n",
        "    # Get The Attribute Values Being Positive And Negative\n",
        "    EntropyAttr = {}\n",
        "    # Attribute Entropy\n",
        "\n",
        "    for att in Attr:\n",
        "        for vals in Attr[att]:\n",
        "            for c in conceptVals:\n",
        "                iData = data[data[att] == vals]\n",
        "                # Get Data For Specific Attribute\n",
        "\n",
        "                dataAtt = iData[iData[concept] == c]\n",
        "                # Get Data For Specific Attribute And Concept\n",
        "\n",
        "                AttrCount[c] = dataAtt.shape[0]\n",
        "                # Get The Count Of Data For Specific Attribute And Concept\n",
        "\n",
        "    TotalInfo = AttrCount[conceptVals[0]] + AttrCount[conceptVals[1]]\n",
        "    # Total Attribute\n",
        "\n",
        "    if AttrCount[conceptVals[0]] == 0 or AttrCount[conceptVals[1]] == 0:\n",
        "        InfoGain = 0\n",
        "    else:\n",
        "        InfoGain = infoGain(AttrCount[conceptVals[0]], AttrCount[conceptVals[1]])\n",
        "        # Calculate InfoGain For Each Attribute\n",
        "\n",
        "    for att in Attr:\n",
        "        if att not in EntropyAttr:\n",
        "            # Calculate Entropy For Each Attribute\n",
        "            EntropyAttr[att] = (TotalInfo / Total) * InfoGain\n",
        "        else:\n",
        "            EntropyAttr[att] = EntropyAttr[att] + (TotalInfo / Total) * InfoGain\n",
        "            # InfoGain\n",
        "\n",
        "    Gain = {}\n",
        "    for g in EntropyAttr:\n",
        "        Gain[g] = ClassEntropy - EntropyAttr[g]\n",
        "        # Calculate Gain\n",
        "    Node = max(Gain, key=Gain.get)\n",
        "    # Get Root Node\n",
        "\n",
        "    tree = insertNode(tree, addTo, Node)\n",
        "    # Add Node To Tree\n",
        "\n",
        "    for nD in Attr[Node]:\n",
        "        tree = insertNode(tree, Node, nD)\n",
        "        # Insert Attribute Value To Tree\n",
        "\n",
        "        newData = data[data[Node] == nD].drop(Node, axis=1)\n",
        "        # Get New Data With Attribute Value nD And Removing Rows With Column Value Node\n",
        "\n",
        "        AttributeList = list(newData)[:-1]\n",
        "        # New Attribute List\n",
        "\n",
        "        tree = getNextNode(newData, AttributeList, concept, conceptVals, tree, nD)\n",
        "        # Call The Function Recursively\n",
        "\n",
        "    return tree\n",
        "\n",
        "def main():\n",
        "    data = pd.read_csv('Datasets/PlayTennis.csv')\n",
        "    # Reading CSV\n",
        "\n",
        "    if 'Unnamed: 0' in data.columns:\n",
        "        data = data.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "    AttributeList = list(data)[:-1]\n",
        "    # Get Attribute List\n",
        "    concept = str(list(data)[-1])\n",
        "    # Get Concept List\n",
        "    conceptVals = list(set(data[concept]))\n",
        "    # Get Concept Values\n",
        "\n",
        "    tree = getNextNode(data, AttributeList, concept, conceptVals, {'root': 'None'}, 'root')\n",
        "\n",
        "    return tree\n",
        "\n",
        "tree = main()['root']\n",
        "df = pd.read_csv('Datasets/PlayTennis.csv')\n",
        "\n",
        "def test(tree, d):\n",
        "    for k in tree:\n",
        "        for v in tree[k]:\n",
        "            if (d[k] == v and isinstance(tree[k][v], dict)):\n",
        "                test(tree[k][v], d)\n",
        "            elif (d[k] == v):\n",
        "                print(\"Classification: \" + tree[k][v])\n",
        "\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "df.head()\n",
        "print(tree)\n",
        "test(tree, df.loc[0, :])\n"
      ],
      "metadata": {
        "id": "9msWxYT8YyNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.Na√ØveBayesianClassifier**"
      ],
      "metadata": {
        "id": "O6GEhMgEauEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def probAttr(data, attr, val):\n",
        "    Total = data.shape[0]\n",
        "    cnt = len(data[data[attr] == val])\n",
        "    return cnt, cnt / Total\n",
        "\n",
        "def train(data, Attr, conceptVals, concept):\n",
        "    conceptProbs = {}\n",
        "    countConcept = {}\n",
        "\n",
        "    for cVal in conceptVals:\n",
        "        countConcept[cVal], conceptProbs[cVal] = probAttr(data, concept, cVal)\n",
        "\n",
        "    AttrConcept = {}\n",
        "    probability_list = {}\n",
        "\n",
        "    for att in Attr:\n",
        "        probability_list[att] = {}\n",
        "        AttrConcept[att] = {}\n",
        "\n",
        "        for val in Attr[att]:\n",
        "            AttrConcept[att][val] = {}\n",
        "            a, probability_list[att][val] = probAttr(data, att, val)\n",
        "\n",
        "            for cVal in conceptVals:\n",
        "                dataTemp = data[data[att] == val]\n",
        "                AttrConcept[att][val][cVal] = len(dataTemp[dataTemp[concept] == cVal]) / countConcept[cVal]\n",
        "\n",
        "    print(\"P(A) : \", conceptProbs,\"\\n\")\n",
        "    print(\"P(X/A) : \", AttrConcept,\"\\n\")\n",
        "    print(\"P(X) : \", probability_list,\"\\n\")\n",
        "\n",
        "    return conceptProbs, AttrConcept, probability_list\n",
        "\n",
        "def test(examples, Attr, concept_list, conceptProbs, AttrConcept, probability_list):\n",
        "    misclassification_count = 0\n",
        "    Total = len(examples)\n",
        "\n",
        "    for ex in examples:\n",
        "        px = {}\n",
        "\n",
        "        for a in Attr:\n",
        "            for x in ex:\n",
        "                for c in concept_list:\n",
        "                    if x in AttrConcept[a]:\n",
        "                        if c not in px:\n",
        "                            px[c] = conceptProbs[c] * AttrConcept[a][x][c] / probability_list[a][x]\n",
        "                        else:\n",
        "                            px[c] = px[c] * AttrConcept[a][x][c] / probability_list[a][x]\n",
        "\n",
        "        print(px)\n",
        "        classification = max(px, key=px.get)\n",
        "        print(\"Classification :\", classification, \"Expected :\", ex[-1])\n",
        "\n",
        "        if classification != ex[-1]:\n",
        "            misclassification_count += 1\n",
        "\n",
        "    misclassification_rate = misclassification_count * 100 / Total\n",
        "    accuracy = 100 - misclassification_rate\n",
        "\n",
        "    print(\"Misclassification Count = {}\".format(misclassification_count))\n",
        "    print(\"Misclassification Rate = {}%\".format(misclassification_rate))\n",
        "    print(\"Accuracy = {}%\".format(accuracy))\n",
        "\n",
        "data = pd.read_csv('Datasets/PlayTennis.csv')\n",
        "data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "print(data)\n",
        "\n",
        "concept = str(list(data)[-1])\n",
        "print(concept)\n",
        "\n",
        "concept_list = set(data[concept])\n",
        "print(concept_list)\n",
        "\n",
        "Attr = {}\n",
        "for a in list(data)[:-1]:\n",
        "    Attr[a] = set(data[a])\n",
        "print(Attr)\n",
        "\n",
        "conceptProbs, AttrConcept, probability_list = train(data, Attr, concept_list, concept)\n",
        "examples = pd.read_csv('Datasets/PlayTennis.csv')\n",
        "test(examples.values, Attr, concept_list, conceptProbs, AttrConcept, probability_list)\n"
      ],
      "metadata": {
        "id": "jWKmOjvyayk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Candidate Elimanation**"
      ],
      "metadata": {
        "id": "Iz2kbfUChrBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Datasets/EnjoySports.csv')\n",
        "# df = df.drop(['slno'], axis=1)\n",
        "concepts = df.values[:, :-1]\n",
        "target = df.values[:, -1]\n",
        "df.head()\n",
        "\n",
        "def learn(concepts, target):\n",
        "    specific_h = concepts[0].copy()\n",
        "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]\n",
        "\n",
        "    for i, h in enumerate(concepts):\n",
        "        if target[i] == \"yes\":\n",
        "            for x in range(len(specific_h)):\n",
        "                if h[x] != specific_h[x]:\n",
        "                    specific_h[x] = '?'\n",
        "                    general_h[x][x] = '?'\n",
        "\n",
        "        if target[i] == \"no\":\n",
        "            for x in range(len(specific_h)):\n",
        "                if h[x] != specific_h[x]:\n",
        "                    general_h[x][x] = specific_h[x]\n",
        "                else:\n",
        "                    general_h[x][x] = '?'\n",
        "\n",
        "    indices = [i for i, val in enumerate(general_h) if val == ['?'] * len(specific_h)]\n",
        "    for i in indices:\n",
        "        general_h.remove(['?'] * len(specific_h))\n",
        "\n",
        "    return specific_h, general_h\n",
        "\n",
        "s_final, g_final = learn(concepts, target)\n",
        "print(f\"Final S : {s_final}\")\n",
        "print(f\"Final G : {g_final}\")\n"
      ],
      "metadata": {
        "id": "lqNW3rGBhwQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.ANN**"
      ],
      "metadata": {
        "id": "xwYdmD4lhzGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
        "y = np.array(([92], [86], [89]), dtype=float)\n",
        "X = X / np.amax(X, axis=0)\n",
        "y = y / 100\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def derivatives_sigmoid(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "epoch = 1000\n",
        "learning_rate = 0.6\n",
        "inputlayer_neurons = 2\n",
        "hiddenlayer_neurons = 3\n",
        "output_neurons = 1\n",
        "\n",
        "wh = np.random.uniform(size=(inputlayer_neurons, hiddenlayer_neurons))\n",
        "bh = np.random.uniform(size=(1, hiddenlayer_neurons))\n",
        "wo = np.random.uniform(size=(hiddenlayer_neurons, output_neurons))\n",
        "bo = np.random.uniform(size=(1, output_neurons))\n",
        "\n",
        "for i in range(epoch):\n",
        "    net_h = np.dot(X, wh) + bh\n",
        "    sigma_h = sigmoid(net_h)\n",
        "    net_o = np.dot(sigma_h, wo) + bo\n",
        "    output = sigmoid(net_o)\n",
        "\n",
        "\n",
        "    deltaK = (y - output) * derivatives_sigmoid(output)\n",
        "    deltaH = deltaK.dot(wo.T) * derivatives_sigmoid(sigma_h)\n",
        "    wo = wo + sigma_h.T.dot(deltaK) * learning_rate\n",
        "    wh = wh + X.T.dot(deltaH) * learning_rate\n",
        "\n",
        "print(\"Input: \\n\" + str(X))\n",
        "print(\"Actual Output: \\n\" + str(y))\n",
        "print(\"Predicted Output: \\n\", output)\n"
      ],
      "metadata": {
        "id": "pUmR1a9eh7-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7.KMeans**"
      ],
      "metadata": {
        "id": "jzv0KAPSivYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = pd.DataFrame(iris.data)\n",
        "y = pd.DataFrame(iris.target)\n",
        "X.columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width']\n",
        "y.columns = ['Targets']\n",
        "\n",
        "model = KMeans(n_clusters=3)\n",
        "model.fit(X)\n",
        "\n",
        "plt.figure(figsize=(14, 14))\n",
        "colormap = np.array(['red', 'lime', 'black'])\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[y.Targets], s=40)\n",
        "plt.title('Real Clusters')\n",
        "plt.xlabel('Petal Length')\n",
        "plt.ylabel('Petal Width')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[model.labels_], s=40)\n",
        "plt.title('K-Means Clustering')\n",
        "plt.xlabel('Petal Length')\n",
        "plt.ylabel('Petal Width')\n",
        "\n",
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X)\n",
        "xsa = scaler.transform(X)\n",
        "xs = pd.DataFrame(xsa, columns=X.columns)\n",
        "\n",
        "from sklearn.mixture import GaussianMixture\n",
        "gmm = GaussianMixture(n_components=3)\n",
        "gmm.fit(xs)\n",
        "gmm_y = gmm.predict(xs)\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[gmm_y], s=40)\n",
        "plt.title('GMM Clustering')\n",
        "plt.xlabel('Petal Length')\n",
        "plt.ylabel('Petal Width')\n",
        "\n",
        "print('Observation: The GMM Using EM Algorithm Based Clustering Matched The True Labels More Closely Than The K-Means.')\n"
      ],
      "metadata": {
        "id": "KsEyt2c_i130"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# 8.KNN**"
      ],
      "metadata": {
        "id": "HcNhhMuGjT3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "dataset = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dataset[\"data\"], dataset[\"target\"], random_state=0\n",
        ")\n",
        "\n",
        "kn = KNeighborsClassifier(n_neighbors=3)\n",
        "kn.fit(X_train, y_train)\n",
        "\n",
        "prediction = kn.predict(X_test)\n",
        "conf_matrix = confusion_matrix(y_test, prediction)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "ir_L_6UBjYPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9.Locally Weighted Regressional**"
      ],
      "metadata": {
        "id": "faIeuoQEjpsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import ceil\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def lowess(x, y, f, iterations):\n",
        "    n = len(x)\n",
        "    r = int(ceil(f * n))\n",
        "    h = [np.sort(np.abs(x - x[i]))[r] for i in range(n)]\n",
        "    w = np.clip(np.abs((x[:, None] - x[None, :]) / h), 0.0, 1.0)\n",
        "    w = (1 - w ** 3) ** 3\n",
        "    yest = np.zeros(n)\n",
        "    delta = np.ones(n)\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "        for i in range(n):\n",
        "            weights = delta * w[:, i]\n",
        "            b = np.array([np.sum(weights * y), np.sum(weights * y * x)])\n",
        "            A = np.array([[np.sum(weights), np.sum(weights * x)],\n",
        "                          [np.sum(weights * x), np.sum(weights * x * x)]])\n",
        "            beta = linalg.solve(A, b)\n",
        "            yest[i] = beta[0] + beta[1] * x[i]\n",
        "\n",
        "        residuals = y - yest\n",
        "        s = np.median(np.abs(residuals))\n",
        "        delta = np.clip(residuals / (6.0 * s), -1, 1)\n",
        "        delta = (1 - delta ** 2) ** 2\n",
        "\n",
        "    return yest\n",
        "\n",
        "def main():\n",
        "    n = 100\n",
        "    x = np.linspace(0, 2 * np.pi, n)\n",
        "    y = np.sin(x) + 0.3 * np.random.randn(n)\n",
        "    f = 0.25\n",
        "    iterations = 3\n",
        "    yest = lowess(x, y, f, iterations)\n",
        "\n",
        "    plt.plot(x, y, \"r.\", label=\"Original Data\")\n",
        "    plt.plot(x, yest, \"b-\", label=\"LOWESS Smoothing\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "vvVzfzMtkO8z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}